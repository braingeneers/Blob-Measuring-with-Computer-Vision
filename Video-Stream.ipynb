{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13c298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Using cached imutils-0.5.4-py3-none-any.whl\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d96db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/\n",
    "\n",
    "# import the necessary packages\n",
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-v\", \"--video\", help=\"path to the (optional) video file\");\n",
    "ap.add_argument(\"-b\", \"--buffer\", type=int, default=64, help=\"max buffer size\");\n",
    "#args = vars(ap.parse_args())\n",
    "buffer = 64\n",
    "# define the lower and upper boundaries of the \"green\"\n",
    "# ball in the HSV color space, then initialize the\n",
    "# list of tracked points\n",
    "greenLower = (29, 86, 6)\n",
    "greenUpper = (64, 255, 255)\n",
    "\n",
    "#pts = deque(maxlen=args[\"buffer\"])\n",
    "pts = deque(maxlen = buffer)\n",
    "\n",
    "# if a video path was not supplied, grab the reference\n",
    "# to the webcam\n",
    "# if not args.get(\"video\", False):\n",
    "#     vs = VideoStream(src=0).start()\n",
    "# # otherwise, grab a reference to the video file\n",
    "# else:\n",
    "#     vs = cv2.VideoCapture(args[\"video\"])\n",
    "\n",
    "vs = VideoStream(src=\"rtsp://advancedcameranode.local:8554/cam\").start()\n",
    "\n",
    "\n",
    "# allow the camera or video file to warm up\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c812cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(blurred, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# construct a mask for the color \"green\", then perform\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# a series of dilations and erosions to remove any small\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# blobs left in the mask\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minRange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreenLower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreenUpper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39merode(mask, \u001b[38;5;28;01mNone\u001b[39;00m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     25\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdilate(mask, \u001b[38;5;28;01mNone\u001b[39;00m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# keep looping\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    frame = vs.read()\n",
    "    # handle the frame from VideoCapture or VideoStream\n",
    "    #frame = frame[1] if args.get(\"video\", False) else frame\n",
    "    # if we are viewing a video and we did not grab a frame,\n",
    "    # then we have reached the end of the video\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "#     plt.imshow(frame)\n",
    "#     plt.show() \n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    # construct a mask for the color \"green\", then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask = cv2.inRange(hsv, greenLower, greenUpper)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "        # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    center = None\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 10:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "                (0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "    # update the points queue\n",
    "    pts.appendleft(center)\n",
    "        # loop over the set of tracked points\n",
    "    for i in range(1, len(pts)):\n",
    "        # if either of the tracked points are None, ignore\n",
    "        # them\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue\n",
    "        # otherwise, compute the thickness of the line and\n",
    "        # draw the connecting lines\n",
    "        thickness = int(np.sqrt(64 / float(i + 1)) * 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "    # show the frame to our screen\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# if we are not using a video file, stop the camera video stream\n",
    "if not args.get(\"video\", False):\n",
    "    vs.stop()\n",
    "# otherwise, release the camera\n",
    "else:\n",
    "    vs.release()\n",
    "# close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad294d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
